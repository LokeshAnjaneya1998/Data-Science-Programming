{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98fbbd9-216d-4ed8-b5a9-39dce6660787",
   "metadata": {},
   "source": [
    "## WE03a-DTrees-model-fit\n",
    "\n",
    "In this notebook we look at using ensembles of models to improve the performance of our models. We will look at the following:\n",
    "* Logestic Regression\n",
    "* Logestic Regression with L2 regularization\n",
    "* RandomForest\n",
    "* AdaBoost\n",
    "* Gradiant Boosting\n",
    "* XG Boosting\n",
    "\n",
    "RandomizedSearchCV, GridSearchCV will be preformed combinely on each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b042a3-6b86-4ab2-a1ea-8062fcd37145",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c36372-3e04-4c62-8992-4047fdc39266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f7677-acc1-4b13-8b9b-399ac2b95b8a",
   "metadata": {},
   "source": [
    "## Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dfaaaa-aec5-4464-a0c0-93deabb19521",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('univbank-train_X-data.csv') \n",
    "y_train = pd.read_csv('univbank-train_y-data.csv') \n",
    "X_test = pd.read_csv('univbank-test_X-data.csv') \n",
    "y_test = pd.read_csv('univbank-test_y-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469e723-0094-47b5-a50b-ca9a02b4618a",
   "metadata": {},
   "source": [
    "## Observing the shapes of the data\n",
    "Complete observations of the data were done in data gen note book. So not doing other observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af71ab95-390e-49af-b7fa-567c4a445038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2e52fe-e34e-480d-b674-b5e2289156ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea293f6-4c57-4138-a0d5-7bef00ef7a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81372178-452e-47c8-91cd-c86ddadbce02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf8398-f3b5-4355-a949-8bb5fd292433",
   "metadata": {},
   "source": [
    "### Storing the results in data frames to display them at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b619148e-89e2-49e8-9e52-052d4243beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = pd.DataFrame({\"model\": [], \"rmse\": []})\n",
    "\n",
    "performance = pd.DataFrame({\"model\": [], 'Best recall': [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf951d-86e9-4988-a368-4aaa4ad4c11a",
   "metadata": {},
   "source": [
    "## Prediction with logestic regression model (using default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3732bcf-9d5e-44f5-9366-952012033f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression()\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14bf20ae-1898-4cef-9ac6-76f023eacd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logestic regression Test RMSE: 0.14832396974191325\n"
     ]
    }
   ],
   "source": [
    "test_pred = log_reg_model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"Log Reg\", 'rmse': test_rmse}, index=[0])])\n",
    "\n",
    "print(f\"Logestic regression Test RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2e330c3-3cb8-4a86-a0de-a4f657adfbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Best recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td></td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model Best recall  Accuracy  Precision   Recall       F1\n",
       "0  default logistic                 0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Best recall': [''],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637f19c-b883-407e-8a9b-c563bf6882ec",
   "metadata": {},
   "source": [
    "## Prediction with logestic regression model (using Random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9002c215-dc88-4f70-9cb5-0ce111138926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The best recall score is 0.6662790697674419\n",
      "... with parameters: {'solver': 'liblinear', 'max_iter': 1000, 'C': 51.489396316718796}\n"
     ]
    }
   ],
   "source": [
    "score_measure = 'recall'\n",
    "param_grid = {\n",
    "    'C': np.random.uniform(0.001, 100, size=100),\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [500, 1000, 1500]\n",
    "}\n",
    "random_search_logreg = RandomizedSearchCV(\n",
    "    estimator=log_reg_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Number of parameter settings to sample\n",
    "    cv=5, scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)   # Number of cross-validation folds\n",
    "_ = random_search_logreg.fit(X_train, np.ravel(y_train))\n",
    "print(f\"The best {score_measure} score is {random_search_logreg.best_score_}\")\n",
    "print(f\"... with parameters: {random_search_logreg.best_params_}\")\n",
    "\n",
    "\n",
    "best_logreg_rand = random_search_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e797d4d7-4908-40b5-9d09-d580f8809df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logestic regression random search Test RMSE: 0.14832396974191325\n"
     ]
    }
   ],
   "source": [
    "test_pred_logreg = random_search_logreg.predict(X_test)\n",
    "test_rmse_logreg = np.sqrt(mean_squared_error(y_test, test_pred_logreg))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"log reg rand\", 'rmse': test_rmse_logreg}, index=[0])])\n",
    "\n",
    "print(f\"Logestic regression random search Test RMSE: {test_rmse_logreg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23cf60c-0019-44a3-b848-5bd482c96761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, test_pred_logreg)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logreg rand\", \n",
    "                                                    'Best recall': [random_search_logreg.best_score_],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f0d15-fd84-4d70-bffb-2f261e48956d",
   "metadata": {},
   "source": [
    "## Prediction with logestic regression model (using exhaustive grid search on Random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5627548-15cc-47e4-adf4-c0318e45cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "The best recall score is 0.6662790697674419\n",
      "... with parameters: {'C': 51.48929631671879, 'max_iter': 998, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "\n",
    "kfolds = 5\n",
    "C = random_search_logreg.best_params_['C']\n",
    "solver = random_search_logreg.best_params_['solver']\n",
    "max_iter = random_search_logreg.best_params_['max_iter']\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-0.0001,C+2),  \n",
    "    'max_iter': np.arange(max_iter-2,max_iter+2), \n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    estimator=log_reg_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5, scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "    return_train_score=True)   # Number of cross-validation folds\n",
    "\n",
    "_ = grid_search_logreg.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search_logreg.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_logreg.best_params_}\")\n",
    "\n",
    "\n",
    "best_logreg_rand = grid_search_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "607edee1-4b81-41eb-b6dd-2c6b0d020ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logestic regression grid search Test RMSE: 0.14832396974191325\n"
     ]
    }
   ],
   "source": [
    "grid_pred_logreg = grid_search_logreg.predict(X_test)\n",
    "grid_rmse_logreg = np.sqrt(mean_squared_error(y_test, grid_pred_logreg))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"log reg grid\", 'rmse': test_rmse_logreg}, index=[0])])\n",
    "\n",
    "print(f\"Logestic regression grid search Test RMSE: {test_rmse_logreg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0c58b7a-462a-45ba-8d54-737d7ca28ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_pred_logreg)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logreg grid\", \n",
    "                                                    'Best recall': [grid_search_logreg.best_score_],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e562b-3727-4b99-ab48-72a34da39596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4194a24-9cfb-4d0b-abc9-00f624d650e0",
   "metadata": {},
   "source": [
    "## Prediction with logestic regression model (using L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5266af4-3034-4050-a94e-cd321b29e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L2_model = LogisticRegression(penalty='l2', max_iter=2000)\n",
    "_ = log_reg_L2_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d70fa0f-24bb-4dff-8fdd-423fd967a41e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Logestic regression Test RMSE: 0.14832396974191325\n"
     ]
    }
   ],
   "source": [
    "test_pred_log = log_reg_L2_model.predict(X_test)\n",
    "test_rmse_log = np.sqrt(mean_squared_error(y_test, test_pred_log))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"L2 Log Reg\", 'rmse': test_rmse_log}, index=[0])])\n",
    "\n",
    "print(f\"L2 Logestic regression Test RMSE: {test_rmse_log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8557b7a1-9258-4806-aaf1-659ab4c2fce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_preds = log_reg_L2_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L2 logistic\",\n",
    "                                                    'Best recall': [''],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c773b7-2c53-441a-a103-b15583f44400",
   "metadata": {},
   "source": [
    "## Prediction with logestic regression model (using L2 Regularization, on Random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2853bcad-e9ee-4b10-8ee9-8161efd7ee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The best recall score is 0.6662790697674419\n",
      "... with parameters: {'solver': 'liblinear', 'max_iter': 500, 'C': 33.80299996295606}\n"
     ]
    }
   ],
   "source": [
    "score_measure = 'recall'\n",
    "param_grid = {\n",
    "    'C': np.random.uniform(0.001, 100, size=100),\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [500, 1000, 1500]\n",
    "}\n",
    "random_search_logregl2 = RandomizedSearchCV(\n",
    "    estimator=log_reg_L2_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Number of parameter settings to sample\n",
    "    cv=5, scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)   # Number of cross-validation folds\n",
    "_ = random_search_logregl2.fit(X_train, np.ravel(y_train))\n",
    "print(f\"The best {score_measure} score is {random_search_logregl2.best_score_}\")\n",
    "print(f\"... with parameters: {random_search_logregl2.best_params_}\")\n",
    "\n",
    "\n",
    "best_logreg_rand = random_search_logregl2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a686db1f-97dc-4ce1-ac6d-a4a250fdb095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logestic regression L2 random search Test RMSE: 0.14832396974191325\n"
     ]
    }
   ],
   "source": [
    "test_pred_logregl2 = random_search_logregl2.predict(X_test)\n",
    "test_rmse_logregl2 = np.sqrt(mean_squared_error(y_test, test_pred_logregl2))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"log reg l2 rand\", 'rmse': test_rmse_logregl2}, index=[0])])\n",
    "\n",
    "print(f\"Logestic regression L2 random search Test RMSE: {test_rmse_logregl2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e65b278-c914-41ec-95a7-a685a4e5c500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, test_pred_logregl2)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logreg L2 rand\", \n",
    "                                                    'Best recall': [random_search_logregl2.best_score_],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd9db3-ac2e-44b3-82a7-8ee4aa5c56ea",
   "metadata": {},
   "source": [
    "## Prediction with logestic regression model (using L2 Regularization, exhaustive grid search on Random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80f6f928-1860-4dc3-ab19-ebbe880010a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "The best recall score is 0.6662790697674419\n",
      "... with parameters: {'C': 33.802899962956054, 'max_iter': 498, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "\n",
    "kfolds = 5\n",
    "C = random_search_logregl2.best_params_['C']\n",
    "solver = random_search_logregl2.best_params_['solver']\n",
    "max_iter = random_search_logregl2.best_params_['max_iter']\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-0.0001,C+2),  \n",
    "    'max_iter': np.arange(max_iter-2,max_iter+2), \n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "grid_search_logregl2 = GridSearchCV(\n",
    "    estimator=log_reg_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5, scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "    return_train_score=True)   # Number of cross-validation folds\n",
    "\n",
    "_ = grid_search_logregl2.fit(X_train, np.ravel(y_train))\n",
    "print(f\"The best {score_measure} score is {grid_search_logregl2.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_logregl2.best_params_}\")\n",
    "\n",
    "\n",
    "best_logreg_rand = grid_search_logregl2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fce3981-1c29-48e2-b305-8350c62d7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logestic regression grid search Test RMSE: 0.14832396974191325\n"
     ]
    }
   ],
   "source": [
    "grid_pred_logregl2 = grid_search_logregl2.predict(X_test)\n",
    "grid_rmse_logregl2 = np.sqrt(mean_squared_error(y_test, grid_pred_logregl2))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"log reg grid\", 'rmse': grid_rmse_logregl2}, index=[0])])\n",
    "\n",
    "print(f\"Logestic regression grid search Test RMSE: {grid_rmse_logregl2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8398db5-76c1-4a34-828e-cd4257ffe391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_pred_logregl2)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logreg grid\", \n",
    "                                                    'Best recall': [grid_search_logregl2.best_score_],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2433a-636f-4563-8000-6c98eceb9a22",
   "metadata": {},
   "source": [
    "## Prediction with Decision Tree (using default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c45e4d09-a6c9-4bda-a23e-9c847f264649",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "362e73d8-2b7f-4a62-b2ef-4a691d5bdc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea54f8f6-f9b0-4103-ad94-054931c171b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descission Tree grid search Test RMSE: 0.2016597794967223\n"
     ]
    }
   ],
   "source": [
    "test_pred_Dtreed = dtree.predict(X_test)\n",
    "test_rmse_Dtreed = np.sqrt(mean_squared_error(y_test, test_pred_Dtreed))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"DTree\", 'rmse': test_rmse_Dtreed}, index=[0])])\n",
    "\n",
    "print(f\"Descission Tree grid search Test RMSE: {test_rmse_Dtreed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6f462a6-0004-489f-afcd-23b709be6775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9593333 Precision=0.6279070 Recall=0.6506024 F1=0.6390533\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, test_pred_Dtreed)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"DTree\", \n",
    "                                                    'Best recall': [''],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb7a8b-cd5a-4327-8ed3-ed80f26995f8",
   "metadata": {},
   "source": [
    "## Prediction with Decision Tree (using grid search and score measure = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ad1e1bf-63ec-4a9e-910c-252ed0b2399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5000 candidates, totalling 25000 fits\n",
      "The best accuracy score is 0.9791428571428572\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 5, 'max_leaf_nodes': 10, 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [2,10,50,100,200],  \n",
    "    'min_samples_leaf': [1,5,10,20,50],\n",
    "    'min_impurity_decrease': [0.0001, 0.0005, 0.0010, 0.0020, 0.0050],\n",
    "    'max_leaf_nodes': [10,25,50,100,200], \n",
    "    'max_depth': [5,10,20,30], \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTreeGrid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55d64f0f-4a6e-4d1a-80d7-3a933514fb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descission Tree grid search Test RMSE: 0.14832396974191325\n"
     ]
    }
   ],
   "source": [
    "test_pred_Dtree = grid_search.predict(X_test)\n",
    "test_rmse_Dtree = np.sqrt(mean_squared_error(y_test, test_pred_Dtree))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"DTree grid\", 'rmse': test_rmse_Dtree}, index=[0])])\n",
    "\n",
    "print(f\"Descission Tree grid search Test RMSE: {test_rmse_Dtree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44a4af27-3723-4fa8-b18a-38b16ab77fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, test_pred_Dtree)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"DTree grid\", \n",
    "                                                    'Best recall': [''],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009381d-0d9d-48c1-b605-5fe38691f7c2",
   "metadata": {},
   "source": [
    "## Prediction with Decision Tree (using random search, score measure is recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61404d29-82d9-41c1-8965-10fade34a489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "The best recall score is 0.712262156448203\n",
      "... with parameters: {'min_samples_split': 100, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.001, 'max_leaf_nodes': 200, 'max_depth': 30, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [5,10,50,100,200],  \n",
    "    'min_samples_leaf': [5,10,20,50, 100],\n",
    "    'min_impurity_decrease': [0.0001, 0.0005, 0.0010, 0.0020, 0.0050],\n",
    "    'max_leaf_nodes': [10,25,50,100,200], \n",
    "    'max_depth': [5,10,20,30], \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=1000,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTreeRand = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e478fde9-fa20-4fa7-9612-2c94c8e691af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descission Tree random search Test RMSE: 0.18439088914585774\n"
     ]
    }
   ],
   "source": [
    "test_pred_randDtree = rand_search.predict(X_test)\n",
    "test_rmse_randDtree = np.sqrt(mean_squared_error(y_test, test_pred_randDtree))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"DTree rand\", 'rmse': test_rmse_randDtree}, index=[0])])\n",
    "\n",
    "print(f\"Descission Tree random search Test RMSE: {test_rmse_randDtree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "789462c3-2c2b-4881-8146-bb4c9960b00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9660 Precision=0.7051 Recall=0.6627 F1=0.6832\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, test_pred_randDtree)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.4f} Precision={TP/(TP+FP):.4f} Recall={TP/(TP+FN):.4f} F1={2*TP/(2*TP+FP+FN):.4f}\")\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Dtree rand\", \n",
    "                                                    'Best recall': [rand_search.best_score_],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3be60-82d4-4ee9-8493-0ca24072b9b3",
   "metadata": {},
   "source": [
    "## Prediction with Decision Tree (using exhaustive grid search on random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "599eea74-2c85-4a02-bc5b-95161ac547bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1280 candidates, totalling 6400 fits\n",
      "The best recall score is 0.712262156448203\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 28, 'max_leaf_nodes': 198, 'min_impurity_decrease': 0.0009, 'min_samples_leaf': 3, 'min_samples_split': 98}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search_exh = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search_exh.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search_exh.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_exh.best_params_}\")\n",
    "\n",
    "bestRecallTreehridexh = grid_search_exh.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45f7e561-a88f-4310-a50d-cb1fd38dd1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descission Tree exhaustive grid search Test RMSE: 0.18439088914585774\n"
     ]
    }
   ],
   "source": [
    "test_pred_gridDtree = grid_search_exh.predict(X_test)\n",
    "test_rmse_gridDtree = np.sqrt(mean_squared_error(y_test, test_pred_gridDtree))\n",
    "\n",
    "rmses = pd.concat([rmses, pd.DataFrame({'model':\"DTree exh grid\", 'rmse': test_rmse_gridDtree}, index=[0])])\n",
    "\n",
    "print(f\"Descission Tree exhaustive grid search Test RMSE: {test_rmse_gridDtree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c71ec96f-2732-48ba-8de4-dba191318526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9660 Precision=0.7051 Recall=0.6627 F1=0.6832\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, test_pred_gridDtree)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.4f} Precision={TP/(TP+FP):.4f} Recall={TP/(TP+FN):.4f} F1={2*TP/(2*TP+FP+FN):.4f}\")\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"DTree exh grid\", \n",
    "                                                    'Best recall': [grid_search_exh.best_score_],\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b482fb0a-d113-43b0-b792-0c4f8293733a",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4831b9e-07d5-4a2b-98ec-7522d11d7218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log Reg</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg rand</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg grid</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 Log Reg</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg l2 rand</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg grid</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree</td>\n",
       "      <td>0.201660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree grid</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree rand</td>\n",
       "      <td>0.184391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree exh grid</td>\n",
       "      <td>0.184391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model      rmse\n",
       "0          Log Reg  0.148324\n",
       "0     log reg rand  0.148324\n",
       "0     log reg grid  0.148324\n",
       "0       L2 Log Reg  0.148324\n",
       "0  log reg l2 rand  0.148324\n",
       "0     log reg grid  0.148324\n",
       "0            DTree  0.201660\n",
       "0       DTree grid  0.148324\n",
       "0       DTree rand  0.184391\n",
       "0   DTree exh grid  0.184391"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d036301d-1ba6-4062-a564-bffc82e50388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Best recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td></td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg rand</td>\n",
       "      <td>0.666279</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg grid</td>\n",
       "      <td>0.666279</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td></td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg L2 rand</td>\n",
       "      <td>0.666279</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg grid</td>\n",
       "      <td>0.666279</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree</td>\n",
       "      <td></td>\n",
       "      <td>0.959333</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.639053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree grid</td>\n",
       "      <td></td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dtree rand</td>\n",
       "      <td>0.712262</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.683230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree exh grid</td>\n",
       "      <td>0.712262</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.683230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model Best recall  Accuracy  Precision    Recall        F1\n",
       "0  default logistic              0.978000   1.000000  0.602410  0.751880\n",
       "0       logreg rand    0.666279  0.978000   1.000000  0.602410  0.751880\n",
       "0       logreg grid    0.666279  0.978000   1.000000  0.602410  0.751880\n",
       "0       L2 logistic              0.978000   1.000000  0.602410  0.751880\n",
       "0    logreg L2 rand    0.666279  0.978000   1.000000  0.602410  0.751880\n",
       "0       logreg grid    0.666279  0.978000   1.000000  0.602410  0.751880\n",
       "0             DTree              0.959333   0.627907  0.650602  0.639053\n",
       "0        DTree grid              0.978000   1.000000  0.602410  0.751880\n",
       "0        Dtree rand    0.712262  0.966000   0.705128  0.662651  0.683230\n",
       "0    DTree exh grid    0.712262  0.966000   0.705128  0.662651  0.683230"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0040b71-a5f7-4aef-b181-4e6434126427",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To evaluate the models' performance, we need to select the most appropriate metric. There are several metrics I used for this task, including RMSE (Root Mean Square Error), accuracy, precision, recall, and the F1 score. \n",
    "\n",
    "1. **RMSE** \n",
    "2. **Accuracy** \n",
    "3. **Precision**\n",
    "4. **Recall** \n",
    "5. **F1 score** \n",
    "\n",
    "\n",
    "* Looking at the models, it seems like Logistic Regression (default, random, grid, L2, L2 random, grid again), and Decision Tree with grid have very similar performance with RMSE 0.148324, 100% accuracy, precision of approximately 60%, recall around 75%, and an F1 score of 0.75.\n",
    "\n",
    "* Meanwhile, the default Decision Tree, Decision Tree with random search, and Decision Tree with exhaustive grid search, have a higher RMSE and lower accuracy, precision, recall, and F1 score.\n",
    "\n",
    "* Given these metrics, it would appear that the Logistic Regression models and the Decision Tree with grid search perform the best. \n",
    "\n",
    "* However, the choice of the 'best' model depends on the problem at hand. To maximizie the number of correct predictions overall, then accuracy would be the best metric, and thus the Logistic Regression and Decision Tree with grid search would be the best models.\n",
    "\n",
    "* Overall, given the similarity across the metrics, the Logistic Regression models or the Decision Tree with grid search as the best models. However, logistic regression models are simpler and often preferable for their interpretability, so unless the Decision Tree model's structure brings some additional value, one of the logistic models might be the best choice. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
